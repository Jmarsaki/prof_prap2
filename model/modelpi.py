# -*- coding: utf-8 -*-
"""SRCpI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CtVb8h__0aZuwgGFJDbrHPyvsqXzq_GO

##Aplicación para reconocimiento de arañas venenosas

Carpeta model de procesamiento de imagenes (modelo entrenado)
"""

# Carga de imagenes en colab desde drive
from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split

# Ruta al directorio que contiene las imágenes de entrenamiento
train_data_dir = '/content/drive/MyDrive/dataset_arañasvenenosas'

# Obtener la lista de imágenes
image_list = os.listdir(train_data_dir)

# Variables para almacenar las imágenes y etiquetas
images = []
labels = []

def obtener_etiqueta(image_name):
    # Lógica para obtener la etiqueta de la imagen
    # ...
    return etiqueta_obtenida

etiqueta_obtenida= 60

# Cargar y procesar las imágenes
for image_name in image_list:
    if image_name.endswith('.jpg'):
        # Cargar la imagen
        image_path = os.path.join(train_data_dir, image_name)
        image = load_img(image_path, target_size=(224, 224))  # Redimensionar la imagen si es necesario
        image_array = img_to_array(image)
# Normalizar los valores de píxeles (opcional)
        image_array = image_array / 255.0

        # Obtener la etiqueta correspondiente a la imagen
        label = obtener_etiqueta(image_name)  # Reemplaza "obtener_etiqueta" con tu lógica para obtener la etiqueta

        # Agregar la imagen y la etiqueta a las listas
        images.append(image_array)
        labels.append(label)

# Convertir las listas en arrays numpy
images = np.array(images)
labels = np.array(labels)

# Dividir los datos en conjuntos de entrenamiento y validación
train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)

# Definir el modelo

num_classes=1

model = tf.keras.Sequential([
    tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False),
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])

# Compilar el modelo
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Entrenar el modelo
model.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=20)

# Guardar el modelo entrenado
model.save('modelo.h5')